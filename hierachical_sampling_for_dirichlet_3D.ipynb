{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hierachical_sampling_for_dirichlet_3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdLyD+y4c/8PRzK5Jsmm63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RebeccaRoberts/phd-codebites/blob/master/hierachical_sampling_for_dirichlet_3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Sampling for Dirichlet update from Polya"
      ],
      "metadata": {
        "id": "Ve9e7hTQevXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the sampling version of the 2D example that we use for ALBU and VB messages. "
      ],
      "metadata": {
        "id": "NPmlN8FKg2yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sampled_message(alphas=[1.2,0.8], p_W_given_Z=[0.8,0.2],N=20000,v=0):\n",
        "\n",
        "  # Sample from the dirichlet\n",
        "  a_samples = np.random.dirichlet(alphas, N)\n",
        "\n",
        "  # Arrays for sampled categorical and its child\n",
        "  Z_samples = np.zeros(len(a_samples))\n",
        "  W_samples = np.zeros(len(a_samples))\n",
        "\n",
        "  i = 0\n",
        "  # Iterate over the samples\n",
        "  for sample in a_samples:\n",
        "    # Sample from the categorical Z\n",
        "    Z_sample = np.random.choice(  \n",
        "      a=list(range(len(sample))),  \n",
        "      size=1,  \n",
        "      p=sample \n",
        "    ) \n",
        "    # Save the sample\n",
        "    Z_samples[i] = Z_sample\n",
        "    \n",
        "    # Sample from the child categorical, W, using Z_sample\n",
        "    W_sample = np.random.choice(  \n",
        "      a=[0, 1],  \n",
        "      size=1,  \n",
        "      p=p_W_given_Z[Z_sample][0] # its a matrix hence the [0]\n",
        "    ) \n",
        "    # Save the sample\n",
        "    W_samples[i] = W_sample\n",
        "    i += 1\n",
        "\n",
        "  # Reshape and stacking\n",
        "  Z_samples = Z_samples.reshape(1,-1)\n",
        "  W_samples = W_samples.reshape(1,-1)\n",
        "  samples = np.hstack((Z_samples.T,W_samples.T))\n",
        "\n",
        "  # Observe v (throw away the rest of the samples)\n",
        "  samples = samples[samples[:,1] == v]\n",
        "\n",
        "  # Total number of samples remaining\n",
        "  sum_V = len(samples)\n",
        "\n",
        "  # List of K categories for Z\n",
        "  obs_list = list(range(len(alphas)))\n",
        "\n",
        "  # Array to store the mixture of alpha and pk vaues\n",
        "  pkak_array = np.zeros(len(alphas))\n",
        "  i = 0\n",
        "  for obs in obs_list:\n",
        "    n_v = len(samples[samples[:,0] == obs])\n",
        "    pkak_array[i] = n_v/sum_V\n",
        "    i +=1\n",
        "  return pkak_array"
      ],
      "metadata": {
        "id": "cFztftyt4s7h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z is of cardinality 3 (K = 3) and W of cardinality 2 (V = 2):"
      ],
      "metadata": {
        "id": "Qo7fxgr86R0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Number of samples\n",
        "N = 200000\n",
        "\n",
        "# Category of W that we observe\n",
        "v = 1 # called v from word in vocab from LDA\n",
        "\n",
        "# Dirichelt alpha parameters\n",
        "alphas = np.array([0.8, 1.2, 2.0])\n",
        "\n",
        "# Set up a conditional distribution: P(W|Z)\n",
        "pW_Z1 = np.array([0.2, 0.8])\n",
        "pW_Z2 = np.array([0.7, 0.3])\n",
        "pW_Z3 = np.array([0.4, 0.6])\n",
        "p_W_given_Z = np.vstack((pW_Z1,pW_Z2)) \n",
        "p_W_given_Z = np.vstack((p_W_given_Z,pW_Z3)) # stacked vertically for convenience\n",
        "\n",
        "\n",
        "pkak_array = get_sampled_message(alphas=alphas, \n",
        "                                 p_W_given_Z=p_W_given_Z,\n",
        "                                 N=N,\n",
        "                                 v=v)\n",
        "\n",
        "\n",
        "print(\"p_k a_k array from sampling:\",pkak_array)\n",
        "\n",
        "alphas_dash = alphas + pkak_array\n",
        "print(\"sampling posterior:\",alphas_dash)\n",
        "\n",
        "\n",
        "# ALBU\n",
        "\n",
        "# Calate the categorical coming back to the dirichlet\n",
        "p_W_equals_v_given_Z = p_W_given_Z.T[v]\n",
        "pZ_given_W_equals_v = p_W_equals_v_given_Z/sum(p_W_equals_v_given_Z)\n",
        "pX = pZ_given_W_equals_v\n",
        "\n",
        "# mixing alphas and incoming probs\n",
        "pkak_array = alphas*pX;\n",
        "pkak_array /= np.sum(pkak_array) # renormalize since it is only one observation\n",
        "print(\"p_k a_k array from ALBU:\",pkak_array)\n",
        "\n",
        "# now add the original alphas to get the posterior dirichlet alphas at the polya node\n",
        "alphas_dash = pkak_array + alphas\n",
        "\n",
        "print('albu posterior:',alphas_dash)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RFJMzrhfDu1",
        "outputId": "6a387f4d-327e-4431-9905-cfadd9cfddc6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_k a_k array from sampling: [0.29169925 0.16362397 0.54467679]\n",
            "sampling posterior: [1.09169925 1.36362397 2.54467679]\n",
            "p_k a_k array from ALBU: [0.29090909 0.16363636 0.54545455]\n",
            "albu posterior: [1.09090909 1.36363636 2.54545455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D example, easier to visualise:"
      ],
      "metadata": {
        "id": "AGKsfCjB5WjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Category of W that we observe\n",
        "v = 0 # called v from word in vocab from LDA\n",
        "\n",
        "# Dirichelt alpha parameters\n",
        "alphas = np.array([0.8, 1.2])\n",
        "\n",
        "# Sample from the dirichlet\n",
        "a_samples = np.random.dirichlet(alphas, N)\n",
        "\n",
        "# Set up a conditional distribution: P(W|Z)\n",
        "pW_Z1 = np.array([0.2, 0.8])\n",
        "pW_Z2 = np.array([0.7, 0.3])\n",
        "p_W_given_Z = np.vstack((pW_Z1,pW_Z2)) # stacked vertically for convenience\n",
        "\n",
        "pkak_array = get_sampled_message(alphas=alphas, \n",
        "                                 p_W_given_Z=p_W_given_Z,\n",
        "                                 N=N,\n",
        "                                 v=v)\n",
        "\n",
        "\n",
        "print(\"p_k a_k array from sampling:\",pkak_array)\n",
        "\n",
        "alphas_dash = alphas + pkak_array\n",
        "print(\"sampling posterior:\",alphas_dash)\n",
        "\n",
        "# ALBU\n",
        "\n",
        "# Calate the categorical coming back to the dirichlet\n",
        "p_W_equals_v_given_Z = p_W_given_Z.T[v]\n",
        "pZ_given_W_equals_v = p_W_equals_v_given_Z/sum(p_W_equals_v_given_Z)\n",
        "pX = pZ_given_W_equals_v\n",
        "\n",
        "# mixing alphas and incoming probs\n",
        "pkak_array = alphas*pX;\n",
        "pkak_array /= np.sum(pkak_array) # renormalize since it is only one observation\n",
        "print(\"p_k a_k array from ALBU:\",pkak_array)\n",
        "\n",
        "# now add the original alphas to get the posterior dirichlet alphas at the polya node\n",
        "alphas_dash = pkak_array + alphas\n",
        "\n",
        "print('albu posterior:',alphas_dash)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN513-3a5QuY",
        "outputId": "bb708f22-7a53-415b-95b1-820f184e8127"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_k a_k array from sampling: [0.15925052 0.84074948]\n",
            "sampling posterior: [0.95925052 2.04074948]\n",
            "p_k a_k array from ALBU: [0.16 0.84]\n",
            "albu posterior: [0.96 2.04]\n"
          ]
        }
      ]
    }
  ]
}